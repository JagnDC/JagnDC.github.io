<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Spark(一) · 初识</title>
    <url>/2020/02/25/Spark%E5%88%9D%E8%AF%86/</url>
    <content><![CDATA[<h1 id="Spark-一-·-初识"><a href="#Spark-一-·-初识" class="headerlink" title="Spark(一) · 初识"></a>Spark(一) · 初识</h1><h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><p>需要的环境</p>
<ul>
<li>Linux</li>
<li>Python : 3.6</li>
<li>Hadoop : 5.7以上</li>
<li>Spark : 2.3.0以上</li>
<li>ElasticSearch : 6.3.0</li>
<li>Kibana : 6.3.0</li>
<li>JDK : 1.8</li>
<li>Azkaban : 3.x</li>
</ul>
<p>掌握技巧</p>
<ul>
<li>tar解压命令</li>
<li>环境的配置</li>
</ul>
<h2 id="PySpark-Spark-Core核心RDD"><a href="#PySpark-Spark-Core核心RDD" class="headerlink" title="PySpark-Spark Core核心RDD"></a>PySpark-Spark Core核心RDD</h2><h3 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h3><h4 id="什么是RDD"><a href="#什么是RDD" class="headerlink" title="什么是RDD"></a>什么是RDD</h4><p>源码： <a href="https://github.com/apache/spark" target="_blank" rel="noopener">https://github.com/apache/spark</a></p>
<p>1) RDD是一个抽象类<br>2) 带泛型，可以支持多种类型</p>
<p>RDD: Resilient Distributed Dataset 弹性 分布式 数据集</p>
<p>Represents an<br>immutable 不可变<br>partitioned collection of elements 分区<br>that can be operated on in parallel. 并行计算</p>
<p>单机存储/计算 ==&gt; 分布式存储/计算</p>
<p>1) 数据的存储: 切割    HDFS的Block<br>2) 数据的计算: 切割(分布式并行计算)    MapReduce/Spark<br>3) 存储+计算: HDFS/S3+MapReduce/Spark</p>
<h4 id="RDD的特性"><a href="#RDD的特性" class="headerlink" title="RDD的特性"></a>RDD的特性</h4><p>Internally, each RDD is characterized by five main properties:</p>
<ul>
<li>A list of partitions</li>
<li>系列的分区/分片</li>
<li>A function for computing each split</li>
<li>操作是对每个分区的</li>
<li>A list of dependencies on other RDDs</li>
<li>RDD存在依赖关系(核心,非常重要)</li>
<li>Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)</li>
<li>分区策略</li>
<li>Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)</li>
<li>数据在哪优先把作业调度到数据所在的节点进行计算</li>
</ul>
<p><strong>五大特性</strong></p>
<ul>
<li>def compute(split: Partition, context: TaskContext): Iterator[T] 特性二</li>
<li>def getPartitions: Array[Partition] 特性一</li>
<li>def getDependencies: Seq[Dependency[_]] = deps 特性三</li>
<li>def getPreferredLocations(split: Partition): Seq[String] = Nil 特性五</li>
<li>val partitioner: Option[Partitioner] = None 特性四</li>
</ul>
<p>有两种方式创建RDD </p>
<ul>
<li><p>把一个集合转成RDD Parallelized Collections</p>
</li>
<li><p>把外部数据集Hadoop的兼容转换成RDD External Datasets</p>
</li>
</ul>
<h3 id="SparkContext-amp-SparkConf"><a href="#SparkContext-amp-SparkConf" class="headerlink" title="SparkContext&amp;SparkConf"></a>SparkContext&amp;SparkConf</h3><p>第一要务:创建SparkContext</p>
<ul>
<li><p>连接到Spark集群:local,standalone,yarn,mesos</p>
</li>
<li><p>通过SparkContext来创建RDD，广播变量到集群</p>
</li>
</ul>
<p>在创建SparkContext之前还需要创建SparkConf(优先级高于系统)</p>
<h3 id="PySpark脚本"><a href="#PySpark脚本" class="headerlink" title="PySpark脚本"></a>PySpark脚本</h3><h3 id="Spark应用程序及开发"><a href="#Spark应用程序及开发" class="headerlink" title="Spark应用程序及开发"></a>Spark应用程序及开发</h3><p>1) IDE: pycharm</p>
<p>2) 设置基本参数: python interceptor  PYTHONPATH SPARK_HOME 2zip包</p>
<p>3) 开发</p>
<p>4) 使用local进行本地测试</p>
<p>提交pyspark应用程序</p>
<pre><code>spark-submit --master local[2] --name sparktest /home/***/*.py</code></pre>]]></content>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>初识Redis</title>
    <url>/2020/02/24/Redis%E5%88%9D%E8%AF%86/</url>
    <content><![CDATA[<h2 id="初识Redis"><a href="#初识Redis" class="headerlink" title="初识Redis"></a>初识Redis</h2><p>Redis是一个开源的、基于内存的数据结构存储器，可以用作数据库、缓存和消息中间件。</p>
<h3 id="我们可以从缓存开始熟悉"><a href="#我们可以从缓存开始熟悉" class="headerlink" title="我们可以从缓存开始熟悉"></a>我们可以从缓存开始熟悉</h3><p>实现一个缓存</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// get value from cache</span></span><br><span class="line"><span class="keyword">String</span> value = <span class="built_in">map</span>.<span class="built_in">get</span>(<span class="string">"someKey"</span>);</span><br><span class="line"><span class="keyword">if</span>(null == value) &#123;</span><br><span class="line"> <span class="comment">// get value from DataBase</span></span><br><span class="line"> value = queryValueFromDB(<span class="string">"someKey"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>HashMap、TreeMap这些都线程不安全，可以用HashTable或者ConcurrentHashMap。</p>
<p>不管你用什么样的Map，它的背后都是key-value的Hash表结构，目的就是为了实现O(1)复杂度的查找算法，Redis也是这样实现的，另一个常用的缓存框架Memcached也是。</p>
<p>Hash表的数据结构是怎样的呢？<br><img src="https://pic1.zhimg.com/80/v2-84e2b36df3700de8417fa052b3ac19b8_hd.jpg" alt="hash"></p>
<p>简单说，Hash表就是一个数组，而这个数组的元素，是一个链表。</p>
<p>为什么元素是链表？理论上，如果我们的数组可以做成无限大，那么每来一个key，我们都可以把它放到一个新的位置。但是这样很明显不可行，数组越大，占用的内存就越大。</p>
<p>所以我们需要限制数组的大小，假设是16，那么计算出key的hash值后，对16取模，得出一个0~15的数，然后放到数组对应的位置上去。</p>
<p>好，现在key1放到index为2的位置，突然又来了一个key9，刚好他也要放到index为2的位置，那咋办，总不能把人家key1给踢掉吧？所以key1的信息必须存储在一个链表结构里面，这样key9来了之后，只需要把key1所在的链表节点的next，指向key9的链表节点即可。</p>
<p>很明显，链表越长，Hash表的查询、插入、删除等操作的性能都会下降，极端情况下，如果全部元素都放到了一个链表里头，复杂度就会降为O(n)，也就和顺序查找算法无异了。（正因如此，Java8里头的HashMap在元素增长到一定程度时会从链表转成一颗红黑树，来减缓查找性能的下降）</p>
<p>怎么解决？rehash。关于rehash，这里就不细讲了，大家可以先了解一下Java HashMap的resize函数，然后再通过这篇文章：<a href="https://medium.com/@kousiknath/a-little-internal-on-redis-key-value-storage-implementation-fdf96bac7453" target="_blank" rel="noopener">A little internal on redis key value storage implementation</a> 去了解Redis的rehash算法，你会惊讶的发现Redis里头居然是两个HashTable。</p>
<h3 id="C-S架构"><a href="#C-S架构" class="headerlink" title="C/S架构"></a>C/S架构</h3><p>作为Redis用户，我们要怎样把数据放到上面提到的Hash表里呢？</p>
<p>我们可以通过Redis的命令行，当然也可以通过各种语言的Redis API，在代码里面对Hash表进行操作，所以我们可以将Redis看作是一个C/S架构，客户端是各种操作，Hash表是服务端。</p>
<p>显然，Client和Server可以是在一台机器上的，也可以不在：</p>
<p><img src="https://pic2.zhimg.com/80/v2-d67c538b3a759800eb8102b5eeefee01_hd.jpg" alt="client"></p>
<p><a href="http://try.redis.io/" target="_blank" rel="noopener">try redis</a>这个网站可以用来熟悉Reids的操作</p>
<p>值得一提的是，Redis的Server是单线程服务器，基于Event-Loop模式来处理Client的请求，这一点和NodeJS很相似。使用单线程的好处包括：</p>
<ul>
<li><p>不必考虑线程安全问题。很多操作都不必加锁，既简化了开发，又提高了性能；</p>
</li>
<li><p>减少线程切换损耗的时间。线程一多，CPU在线程之间切来切去是非常耗时的，单线程服务器则没有了这个烦恼；</p>
</li>
</ul>
<p>当然，单线程服务器最大的问题自然是无法充分利用多处理器。</p>
<h3 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h3><p>搭起这样一个框架，一台客户端，一台Redis缓存服务器</p>
<p>随着系统中使用Redis的客户端越来越多，会带来两个问题：</p>
<ul>
<li>Redis内存不足：随着使用Redis的客户端越来越多，Redis上的缓存数据也越来越大，而一台机器的内存毕竟是有限的，放不了那么多数据；</li>
<li>Redis吞吐量低：客户端变多了，可Redis还是只有一台，而且我们已经知道，Redis是单线程的！一台机器的带宽和处理器都是有限的，Redis自然会忙不过来，吞吐量已经不足以支撑我们越来越庞大的系统。</li>
</ul>
<p>可以通过集群的方式解决问题</p>
<p><img src="https://pic1.zhimg.com/80/v2-3ea442fd9cfba7ae0569f40e764dd8f0_hd.jpg" alt="集群"></p>
<p>客户端的请求会通过负载均衡算法（通常是一致性Hash），分散到各个Redis服务器上。</p>
<p>通过集群，我们实现了两个特性：</p>
<ul>
<li>扩大缓存容量；</li>
<li>提升吞吐量；</li>
</ul>
<p>解决了上面提到的两个问题。</p>
<h3 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h3><p>现在我们已经把Redis升级到了集群，真可谓效果杠杠的，可运行了一段时间后，运维又过来反馈了两个问题：</p>
<ul>
<li>数据可用性差：如果其中一台Redis挂了，那么上面全部的缓存数据都会丢失，导致原来可以从缓存中获取的请求，都去访问数据库了，数据库压力陡增。</li>
<li>数据查询缓慢：监测发现，每天有一段时间，Redis 1的访问量非常高，而且大多数请求都是去查一个相同的缓存数据，导致Redis 1非常忙碌，吞吐量不足以支撑这个高的查询负载。</li>
</ul>
<p>问题分析完，要想解决可用性问题，我们第一个想到的，就是数据库里头经常用到的Master-Slave模式，于是，我们给每一台Redis都加上了一台Slave：</p>
<p><img src="https://pic4.zhimg.com/80/v2-b971a5e0d88583cdb8c5c550b5e5b2ab_hd.jpg" alt="slave"></p>
<p>通过Master-Slave模式，我们又实现了两个特性：</p>
<ul>
<li>数据高可用：Master负责接收客户端的写入请求，将数据写到Master后，同步给Slave，实现数据备份。一旦Master挂了，可以将Slave提拔为Master；</li>
<li>提高查询效率：一旦Master发现自己忙不过来了，可以把一些查询请求，转发给Slave去处理，也就是Master负责读写或者只负责写，Slave负责读；</li>
</ul>
<p>为了让Master-Slave模式发挥更大的威力，我们当然可以放更多的Slave，就像这样：</p>
<p><img src="https://pic4.zhimg.com/80/v2-76238e772c8bb5feaa5bb20e4207cfcf_hd.jpg" alt="更多slave"></p>
<p>可这样又引发了另一个问题，那就是Master进行数据备份的工作量变大了，Slava每增加一个，Master就要多备份一次，于是又有了Master/slave chains的架构：</p>
<p><img src="https://pic1.zhimg.com/80/v2-eb813169598035287738730a5f53c2cc_hd.jpg" alt="chains"></p>
<p>这样最顶层的Master的备份压力就没那么大了，它只需要备份两次，然后让那它底下的那两台Slave再去和他们的Slave备份。</p>
<p>事实上，Redis内部要处理的问题还有很多：</p>
<ul>
<li>数据结构。文章一开头提到了，Redis不仅仅是数据存储器，而是数据结构存储器。那是因为Redis支持客户端直接往里面塞各种类型的数据结构，比如String、List、Set、SortedSet、Map等等。你或许会问，这很了不起吗？我自己在Java里写一个HashTable不也可以放各种数据结构？呵呵，要知道你的HashTable只能放Java对象，人家那可是支持多语言的，不管你的客户端是Java还是Python还是别的，都可以往Redis塞数据结构。这一点也是Redis和Memcached相比，非常不同的一点。当然Redis要支持数据结构存储，是以牺牲更多内存为代价的，正所谓有利必有弊。关于Redis里头的数据结构，大家可以参考：<a href="https://redis.io/topics/data-types-intro" target="_blank" rel="noopener">Redis Data Types</a></li>
<li>剔除策略。缓存数据总不能无限增长吧，总得剔除掉一些数据，好让新的缓存数据放进来吧？这就需要LRU算法了，大家可以参考：<a href="https://redis.io/topics/lru-cache" target="_blank" rel="noopener">Redis Lru Cache</a></li>
<li>负载均衡。用到了集群，就免不了需要用到负载均衡，用什么负载均衡算法？在哪里使用负载均衡？这点大家可以参考：<a href="https://redis.io/topics/partitioning" target="_blank" rel="noopener">Redis Partitioning</a></li>
<li>Presharding。如果一开始只有三台Redis服务器，后来发现需要加多一台才能满足业务需要，要怎么办？Redis提供了一种策略，叫：<a href="https://redis.io/topics/partitioning#presharding" target="_blank" rel="noopener">Presharding</a></li>
<li>数据持久化。如果我的机器突然全部断电了，我的缓存数据还能恢复吗？Redis说，相信我，可以的，不然我怎么用作数据库？去看看这个：<a href="https://redis.io/topics/persistence" target="_blank" rel="noopener">Redis Persistence</a>]</li>
<li>数据同步。这篇文章里提到了主从复制，那么Redis是怎么进行主从复制的呢？根据CAP理论，既然我们已经选择了集群，也就是P，分区容忍性，那么剩下那两个，Consistency和Availability只能选择一个了，那么Redis到底是支持最终一致性还是强一致性呢？可以参考：<a href="https://redis.io/topics/replication" target="_blank" rel="noopener">Redis Replication</a></li>
</ul>
<blockquote>
<p>参考知乎<a href="https://zhuanlan.zhihu.com/p/37055648" target="_blank" rel="noopener">Redis简明教程</a></p>
</blockquote>
]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/02/15/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
