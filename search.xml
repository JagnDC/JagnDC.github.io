<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>SQL</title>
    <url>/2020/03/09/SQL/</url>
    <content><![CDATA[<p><img src="/JagnDC/2020/03/09/SQL/DBMS.png" alt="img"></p>
]]></content>
  </entry>
  <entry>
    <title>SQL (一) · 基础学习</title>
    <url>/2020/03/08/SQL_1/</url>
    <content><![CDATA[<h1 id="SQL-一-·-基础学习"><a href="#SQL-一-·-基础学习" class="headerlink" title="SQL (一) · 基础学习"></a>SQL (一) · 基础学习</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>在我们的日常工作中，使用的是类似 MySQL、Oracle 这种的数据库管理系统，实际上这些数据库管理系统都遵循 SQL 语言，这就意味着，我们在使用这些数据库的时候，都是通过 SQL 语言与它们打交道。所以对于从事编程或者互联网行业的人来说，最具有中台能力的语言便是 SQL 语言。自从 SQL 加入了 TIOBE 编程语言排行榜，就一直保持在 Top 10。</p>
<p>SQL 语言按照功能划分成以下的 4 个部分：</p>
<ul>
<li><p>DDL，英文叫做 Data Definition Language，也就是数据定义语言，它用来定义我们的数据库对象，包括数据库、数据表和列。通过使用 DDL，我们可以创建，删除和修改数据库和表结构。</p>
</li>
<li><p>DML，英文叫做 Data Manipulation Language，数据操作语言，我们用它操作和数据库相关的记录，比如增加、删除、修改数据表中的记录。</p>
</li>
<li><p>DCL，英文叫做 Data Control Language，数据控制语言，我们用它来定义访问权限和安全级别。</p>
</li>
<li><p>DQL，英文叫做 Data Query Language，数据查询语言，我们用它查询想要的记录，它是 SQL 语言的重中之重。在实际的业务中，我们绝大多数情况下都是在和查询打交道，因此学会编写正确且高效的查询语句，是学习的重点。</p>
<h4 id="大小写问题"><a href="#大小写问题" class="headerlink" title="大小写问题"></a>大小写问题</h4><ul>
<li>表名、表别名、字段名、字段别名等都小写；</li>
<li>SQL 保留字、函数名、绑定变量等都大写;</li>
<li>此外在数据表的字段名推荐采用下划线命名。</li>
</ul>
<h4 id="DB、DBS-和-DBMS-的区别是什么"><a href="#DB、DBS-和-DBMS-的区别是什么" class="headerlink" title="DB、DBS 和 DBMS 的区别是什么"></a>DB、DBS 和 DBMS 的区别是什么</h4><p>说到 DBMS，有一些概念你需要了解。</p>
</li>
<li><p>DBMS 的英文全称是 DataBase Management System，数据库管理系统，实际上它可以对多个数据库进行管理，所以你可以理解为 DBMS = 多个数据库（DB） + 管理程序。</p>
</li>
<li><p>DB 的英文是 DataBase，也就是数据库。数据库是存储数据的集合，你可以把它理解为多个数据表。</p>
</li>
<li><p>DBS 的英文是 DataBase System，数据库系统。它是更大的概念，包括了数据库、数据库管理系统以及数据库管理人员 DBA。</p>
</li>
</ul>
<p><img src="/JagnDC/2020/03/08/SQL_1/DBMS.png" alt="&#39;DBMS&#39;"></p>
<h4 id="MySQL-中的-SQL-是如何执行的"><a href="#MySQL-中的-SQL-是如何执行的" class="headerlink" title="MySQL 中的 SQL 是如何执行的"></a>MySQL 中的 SQL 是如何执行的</h4><p> 首先 MySQL 是典型的 C/S 架构，即 Client/Server 架构，服务器端程序使用的 mysqld。整体的 MySQL 流程如下图所示：</p>
<p><img src="/JagnDC/2020/03/08/SQL_1/MySQL.png" alt="&#39;DBMS&#39;"></p>
<p> MySQL 由三层组成：</p>
<ul>
<li><p>连接层：客户端和服务器端建立连接，客户端发送 SQL 至服务器端；</p>
</li>
<li><p>SQL 层：对 SQL 语句进行查询处理；</p>
</li>
<li><p>存储引擎层：与数据库文件打交道，负责数据的存储和读取。</p>
<p>SQL层的结构：</p>
</li>
<li><p>查询缓存：Server 如果在查询缓存中发现了这条 SQL 语句，就会直接将结果返回给客户端；如果没有，就进入到解析器阶段。需要说明的是，因为查询缓存往往效率不高，所以在 MySQL8.0 之后就抛弃了这个功能。</p>
</li>
<li><p>解析器：在解析器中对 SQL 语句进行语法分析、语义分析。</p>
</li>
<li><p>优化器：在优化器中会确定 SQL 语句的执行路径，比如是根据全表检索，还是根据索引来检索等。</p>
</li>
<li><p>执行器：在执行之前需要判断该用户是否具备权限，如果具备权限就执行 SQL 查询并返回结果。在 MySQL8.0 以下的版本，如果设置了查询缓存，这时会将查询结果进行缓存。</p>
<p>SQL 语句在 MySQL 中的流程是：</p>
<p>SQL 语句→缓存查询→解析器→优化器→执行器</p>
</li>
</ul>
<p>MySQL 的存储引擎采用了插件的形式，每个存储引擎都面向一种特定的数据库应用环境。同时开源的 MySQL 还允许开发人员设置自己的存储引擎，下面是一些常见的存储引擎：</p>
<ul>
<li>InnoDB 存储引擎：它是 MySQL 5.5 版本之后默认的存储引擎，最大的特点是支持事务、行级锁定、外键约束等。</li>
<li>MyISAM 存储引擎：在 MySQL 5.5 版本之前是默认的存储引擎，不支持事务，也不支持外键，最大的特点是速度快，占用资源少。</li>
<li>Memory 存储引擎：使用系统内存作为存储介质，以便得到更快的响应速度。不过如果 mysqld 进程崩溃，则会导致所有的数据丢失，因此我们只有当数据是临时的情况下才使用 Memory 存储引擎。</li>
<li>NDB 存储引擎：也叫做 NDB Cluster 存储引擎，主要用于 MySQL Cluster 分布式集群环境，类似于 Oracle 的 RAC 集群。</li>
<li>Archive 存储引擎：它有很好的压缩机制，用于文件归档，在请求写入时会进行压缩，所以也经常用来做仓库。</li>
</ul>
<p> 数据库的设计在于表的设计，而在 MySQL 中每个表的设计都可以采用不同的存储引擎，我们可以根据实际的数据处理需要来选择存储引擎，这也是 MySQL 的强大之处。</p>
<p>WHERE 子句中同时出现 AND 和 OR 操作符的时候，需要考虑到执行的先后顺序，也就是两个操作符执行的优先级。一般来说 () 优先级最高，其次优先级是 AND，然后是 OR。</p>
<p><img src="/JagnDC/2020/03/08/SQL_1/WHERE.png" alt="&#39;where&#39;"></p>
<h4 id="常见SQL函数"><a href="#常见SQL函数" class="headerlink" title="常见SQL函数"></a>常见SQL函数</h4><ol>
<li>算术函数<ul>
<li>ABS() 绝对值</li>
<li>MOD() 取余</li>
<li>ROUND() 四舍五入</li>
</ul>
</li>
<li>字符串函数<ul>
<li>CONCAT() 拼接</li>
<li>LENGTH() 字段长度 汉字算三个 数字字母为一</li>
<li>CHAR_LENGTH() 字段长度 汉字数字字母都为一个</li>
<li>LOWER() 转小写</li>
<li>UPPER() 转大写</li>
<li>REPLACE() 替换</li>
<li>SUBSTRING() 截取</li>
</ul>
</li>
<li>日期函数<ul>
<li>CURRENT_DATE() 当前日期</li>
<li>CURRENT_TIME() 当前时间无日期</li>
<li>CURRENT_TIMESTAMP() 日期加时间</li>
<li>EXTRACT() 抽取年月日</li>
<li>DATE() YEAR() MONTH() DAY() HOUR() MINUTE() SECOND() 时间的各个部分 </li>
</ul>
</li>
<li>转换函数<ul>
<li>CAST() 数据类型转换</li>
<li>COALESCE 返回第一个非空值</li>
</ul>
</li>
<li>聚集函数<ul>
<li>COUNT() 总行数</li>
<li>MAX() MIN() 最大最小值</li>
<li>SUM() 求和</li>
<li>AVG() 平均值</li>
<li>DISTINCT() 取唯一</li>
</ul>
</li>
</ol>
<p>在 SQL 中，你还是要确定大小写的规范，因为在 Linux 和 Windows 环境下，可能会遇到不同的大小写问题。</p>
<p>比如 MySQL 在 Linux 的环境下，数据库名、表名、变量名是严格区分大小写的，而字段名是忽略大小写的。</p>
<p>而 MySQL 在 Windows 的环境下全部不区分大小写。</p>
<p><img src="/JagnDC/2020/03/08/SQL_1/SQL.png" alt="SQL"></p>
<h4 id="HAVING"><a href="#HAVING" class="headerlink" title="HAVING"></a>HAVING</h4><p>对于分组的筛选，我们一定要用 HAVING，而不是 WHERE。另外，HAVING 支持所有 WHERE 的操作，因此所有需要 WHERE 子句实现的功能，都可以使用 HAVING 对分组进行筛选。</p>
<p>用 WHERE 进行数据量的过滤，用 GROUP BY 进行分组，用 HAVING 进行分组过滤，用 ORDER BY 进行排序。</p>
<p> <strong>要记住，在 SELECT 查询中，关键字的顺序是不能颠倒的，它们的顺序是：</strong></p>
<pre><code>SELECT ... FROM ... WHERE ... GROUP BY ... HAVING ... ORDER BY ...</code></pre><h4 id="关联子查询，非关联子查询"><a href="#关联子查询，非关联子查询" class="headerlink" title="关联子查询，非关联子查询"></a>关联子查询，非关联子查询</h4><p>子查询虽然是一种嵌套查询的形式，不过我们依然可以依据子查询是否执行多次，从而将子查询划分为关联子查询和非关联子查询。</p>
<ul>
<li><p>子查询从数据表中查询了数据结果，如果这个数据结果只执行一次，然后这个数据结果作为主查询的条件进行执行，那么这样的子查询叫做非关联子查询。</p>
</li>
<li><p>同样，如果子查询需要执行多次，即采用循环的方式，先从外部查询开始，每次都传入子查询进行查询，然后再将结果反馈给外部，这种嵌套的执行方式就称为关联子查询。</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark(二) · 核心编程</title>
    <url>/2020/02/26/Spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="Spark-二-·-核心编程"><a href="#Spark-二-·-核心编程" class="headerlink" title="Spark(二) · 核心编程"></a>Spark(二) · 核心编程</h1>]]></content>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark(一) · 初识</title>
    <url>/2020/02/25/Spark%E5%88%9D%E8%AF%86/</url>
    <content><![CDATA[<h1 id="Spark-一-·-初识"><a href="#Spark-一-·-初识" class="headerlink" title="Spark(一) · 初识"></a>Spark(一) · 初识</h1><h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><p>需要的环境</p>
<ul>
<li>Linux</li>
<li>Python : 3.6</li>
<li>Hadoop : 5.7以上</li>
<li>Spark : 2.3.0以上</li>
<li>ElasticSearch : 6.3.0</li>
<li>Kibana : 6.3.0</li>
<li>JDK : 1.8</li>
<li>Azkaban : 3.x</li>
</ul>
<p>掌握技巧</p>
<ul>
<li>tar解压命令</li>
<li>环境的配置</li>
</ul>
<h2 id="PySpark-Spark-Core核心RDD"><a href="#PySpark-Spark-Core核心RDD" class="headerlink" title="PySpark-Spark Core核心RDD"></a>PySpark-Spark Core核心RDD</h2><h3 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h3><h4 id="什么是RDD"><a href="#什么是RDD" class="headerlink" title="什么是RDD"></a>什么是RDD</h4><p>源码： <a href="https://github.com/apache/spark" target="_blank" rel="noopener">https://github.com/apache/spark</a></p>
<p>1) RDD是一个抽象类<br>2) 带泛型，可以支持多种类型</p>
<p>RDD: Resilient Distributed Dataset 弹性 分布式 数据集</p>
<p>Represents an<br>immutable 不可变<br>partitioned collection of elements 分区<br>that can be operated on in parallel. 并行计算</p>
<p>单机存储/计算 ==&gt; 分布式存储/计算</p>
<p>1) 数据的存储: 切割    HDFS的Block<br>2) 数据的计算: 切割(分布式并行计算)    MapReduce/Spark<br>3) 存储+计算: HDFS/S3+MapReduce/Spark</p>
<h4 id="RDD的特性"><a href="#RDD的特性" class="headerlink" title="RDD的特性"></a>RDD的特性</h4><p>Internally, each RDD is characterized by five main properties:</p>
<ul>
<li>A list of partitions</li>
<li>系列的分区/分片</li>
<li>A function for computing each split</li>
<li>操作是对每个分区的</li>
<li>A list of dependencies on other RDDs</li>
<li>RDD存在依赖关系(核心,非常重要)</li>
<li>Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned)</li>
<li>分区策略</li>
<li>Optionally, a list of preferred locations to compute each split on (e.g. block locations for an HDFS file)</li>
<li>数据在哪优先把作业调度到数据所在的节点进行计算</li>
</ul>
<p><strong>五大特性</strong></p>
<ul>
<li>def compute(split: Partition, context: TaskContext): Iterator[T] 特性二</li>
<li>def getPartitions: Array[Partition] 特性一</li>
<li>def getDependencies: Seq[Dependency[_]] = deps 特性三</li>
<li>def getPreferredLocations(split: Partition): Seq[String] = Nil 特性五</li>
<li>val partitioner: Option[Partitioner] = None 特性四</li>
</ul>
<p>有两种方式创建RDD </p>
<ul>
<li><p>把一个集合转成RDD Parallelized Collections</p>
</li>
<li><p>把外部数据集Hadoop的兼容转换成RDD External Datasets</p>
</li>
</ul>
<h3 id="SparkContext-amp-SparkConf"><a href="#SparkContext-amp-SparkConf" class="headerlink" title="SparkContext&amp;SparkConf"></a>SparkContext&amp;SparkConf</h3><p>第一要务:创建SparkContext</p>
<ul>
<li><p>连接到Spark集群:local,standalone,yarn,mesos</p>
</li>
<li><p>通过SparkContext来创建RDD，广播变量到集群</p>
</li>
</ul>
<p>在创建SparkContext之前还需要创建SparkConf(优先级高于系统)</p>
<h3 id="PySpark脚本"><a href="#PySpark脚本" class="headerlink" title="PySpark脚本"></a>PySpark脚本</h3><h3 id="Spark应用程序及开发"><a href="#Spark应用程序及开发" class="headerlink" title="Spark应用程序及开发"></a>Spark应用程序及开发</h3><p>1) IDE: pycharm</p>
<p>2) 设置基本参数: python interceptor  PYTHONPATH SPARK_HOME 2zip包</p>
<p>3) 开发</p>
<p>4) 使用local进行本地测试</p>
<p>提交pyspark应用程序</p>
<pre><code>spark-submit --master local[2] --name sparktest /home/***/*.py</code></pre>]]></content>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>初识Redis</title>
    <url>/2020/02/24/Redis%E5%88%9D%E8%AF%86/</url>
    <content><![CDATA[<h2 id="初识Redis"><a href="#初识Redis" class="headerlink" title="初识Redis"></a>初识Redis</h2><p>Redis是一个开源的、基于内存的数据结构存储器，可以用作数据库、缓存和消息中间件。</p>
<h3 id="我们可以从缓存开始熟悉"><a href="#我们可以从缓存开始熟悉" class="headerlink" title="我们可以从缓存开始熟悉"></a>我们可以从缓存开始熟悉</h3><p>实现一个缓存</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// get value from cache</span></span><br><span class="line"><span class="keyword">String</span> value = <span class="built_in">map</span>.<span class="built_in">get</span>(<span class="string">"someKey"</span>);</span><br><span class="line"><span class="keyword">if</span>(null == value) &#123;</span><br><span class="line"> <span class="comment">// get value from DataBase</span></span><br><span class="line"> value = queryValueFromDB(<span class="string">"someKey"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>HashMap、TreeMap这些都线程不安全，可以用HashTable或者ConcurrentHashMap。</p>
<p>不管你用什么样的Map，它的背后都是key-value的Hash表结构，目的就是为了实现O(1)复杂度的查找算法，Redis也是这样实现的，另一个常用的缓存框架Memcached也是。</p>
<p>Hash表的数据结构是怎样的呢？<br><img src="https://pic1.zhimg.com/80/v2-84e2b36df3700de8417fa052b3ac19b8_hd.jpg" alt="hash"></p>
<p>简单说，Hash表就是一个数组，而这个数组的元素，是一个链表。</p>
<p>为什么元素是链表？理论上，如果我们的数组可以做成无限大，那么每来一个key，我们都可以把它放到一个新的位置。但是这样很明显不可行，数组越大，占用的内存就越大。</p>
<p>所以我们需要限制数组的大小，假设是16，那么计算出key的hash值后，对16取模，得出一个0~15的数，然后放到数组对应的位置上去。</p>
<p>好，现在key1放到index为2的位置，突然又来了一个key9，刚好他也要放到index为2的位置，那咋办，总不能把人家key1给踢掉吧？所以key1的信息必须存储在一个链表结构里面，这样key9来了之后，只需要把key1所在的链表节点的next，指向key9的链表节点即可。</p>
<p>很明显，链表越长，Hash表的查询、插入、删除等操作的性能都会下降，极端情况下，如果全部元素都放到了一个链表里头，复杂度就会降为O(n)，也就和顺序查找算法无异了。（正因如此，Java8里头的HashMap在元素增长到一定程度时会从链表转成一颗红黑树，来减缓查找性能的下降）</p>
<p>怎么解决？rehash。关于rehash，这里就不细讲了，大家可以先了解一下Java HashMap的resize函数，然后再通过这篇文章：<a href="https://medium.com/@kousiknath/a-little-internal-on-redis-key-value-storage-implementation-fdf96bac7453" target="_blank" rel="noopener">A little internal on redis key value storage implementation</a> 去了解Redis的rehash算法，你会惊讶的发现Redis里头居然是两个HashTable。</p>
<h3 id="C-S架构"><a href="#C-S架构" class="headerlink" title="C/S架构"></a>C/S架构</h3><p>作为Redis用户，我们要怎样把数据放到上面提到的Hash表里呢？</p>
<p>我们可以通过Redis的命令行，当然也可以通过各种语言的Redis API，在代码里面对Hash表进行操作，所以我们可以将Redis看作是一个C/S架构，客户端是各种操作，Hash表是服务端。</p>
<p>显然，Client和Server可以是在一台机器上的，也可以不在：</p>
<p><img src="https://pic2.zhimg.com/80/v2-d67c538b3a759800eb8102b5eeefee01_hd.jpg" alt="client"></p>
<p><a href="http://try.redis.io/" target="_blank" rel="noopener">try redis</a>这个网站可以用来熟悉Reids的操作</p>
<p>值得一提的是，Redis的Server是单线程服务器，基于Event-Loop模式来处理Client的请求，这一点和NodeJS很相似。使用单线程的好处包括：</p>
<ul>
<li><p>不必考虑线程安全问题。很多操作都不必加锁，既简化了开发，又提高了性能；</p>
</li>
<li><p>减少线程切换损耗的时间。线程一多，CPU在线程之间切来切去是非常耗时的，单线程服务器则没有了这个烦恼；</p>
</li>
</ul>
<p>当然，单线程服务器最大的问题自然是无法充分利用多处理器。</p>
<h3 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h3><p>搭起这样一个框架，一台客户端，一台Redis缓存服务器</p>
<p>随着系统中使用Redis的客户端越来越多，会带来两个问题：</p>
<ul>
<li>Redis内存不足：随着使用Redis的客户端越来越多，Redis上的缓存数据也越来越大，而一台机器的内存毕竟是有限的，放不了那么多数据；</li>
<li>Redis吞吐量低：客户端变多了，可Redis还是只有一台，而且我们已经知道，Redis是单线程的！一台机器的带宽和处理器都是有限的，Redis自然会忙不过来，吞吐量已经不足以支撑我们越来越庞大的系统。</li>
</ul>
<p>可以通过集群的方式解决问题</p>
<p><img src="https://pic1.zhimg.com/80/v2-3ea442fd9cfba7ae0569f40e764dd8f0_hd.jpg" alt="集群"></p>
<p>客户端的请求会通过负载均衡算法（通常是一致性Hash），分散到各个Redis服务器上。</p>
<p>通过集群，我们实现了两个特性：</p>
<ul>
<li>扩大缓存容量；</li>
<li>提升吞吐量；</li>
</ul>
<p>解决了上面提到的两个问题。</p>
<h3 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h3><p>现在我们已经把Redis升级到了集群，真可谓效果杠杠的，可运行了一段时间后，运维又过来反馈了两个问题：</p>
<ul>
<li>数据可用性差：如果其中一台Redis挂了，那么上面全部的缓存数据都会丢失，导致原来可以从缓存中获取的请求，都去访问数据库了，数据库压力陡增。</li>
<li>数据查询缓慢：监测发现，每天有一段时间，Redis 1的访问量非常高，而且大多数请求都是去查一个相同的缓存数据，导致Redis 1非常忙碌，吞吐量不足以支撑这个高的查询负载。</li>
</ul>
<p>问题分析完，要想解决可用性问题，我们第一个想到的，就是数据库里头经常用到的Master-Slave模式，于是，我们给每一台Redis都加上了一台Slave：</p>
<p><img src="https://pic4.zhimg.com/80/v2-b971a5e0d88583cdb8c5c550b5e5b2ab_hd.jpg" alt="slave"></p>
<p>通过Master-Slave模式，我们又实现了两个特性：</p>
<ul>
<li>数据高可用：Master负责接收客户端的写入请求，将数据写到Master后，同步给Slave，实现数据备份。一旦Master挂了，可以将Slave提拔为Master；</li>
<li>提高查询效率：一旦Master发现自己忙不过来了，可以把一些查询请求，转发给Slave去处理，也就是Master负责读写或者只负责写，Slave负责读；</li>
</ul>
<p>为了让Master-Slave模式发挥更大的威力，我们当然可以放更多的Slave，就像这样：</p>
<p><img src="https://pic4.zhimg.com/80/v2-76238e772c8bb5feaa5bb20e4207cfcf_hd.jpg" alt="更多slave"></p>
<p>可这样又引发了另一个问题，那就是Master进行数据备份的工作量变大了，Slava每增加一个，Master就要多备份一次，于是又有了Master/slave chains的架构：</p>
<p><img src="https://pic1.zhimg.com/80/v2-eb813169598035287738730a5f53c2cc_hd.jpg" alt="chains"></p>
<p>这样最顶层的Master的备份压力就没那么大了，它只需要备份两次，然后让那它底下的那两台Slave再去和他们的Slave备份。</p>
<p>事实上，Redis内部要处理的问题还有很多：</p>
<ul>
<li>数据结构。文章一开头提到了，Redis不仅仅是数据存储器，而是数据结构存储器。那是因为Redis支持客户端直接往里面塞各种类型的数据结构，比如String、List、Set、SortedSet、Map等等。你或许会问，这很了不起吗？我自己在Java里写一个HashTable不也可以放各种数据结构？呵呵，要知道你的HashTable只能放Java对象，人家那可是支持多语言的，不管你的客户端是Java还是Python还是别的，都可以往Redis塞数据结构。这一点也是Redis和Memcached相比，非常不同的一点。当然Redis要支持数据结构存储，是以牺牲更多内存为代价的，正所谓有利必有弊。关于Redis里头的数据结构，大家可以参考：<a href="https://redis.io/topics/data-types-intro" target="_blank" rel="noopener">Redis Data Types</a></li>
<li>剔除策略。缓存数据总不能无限增长吧，总得剔除掉一些数据，好让新的缓存数据放进来吧？这就需要LRU算法了，大家可以参考：<a href="https://redis.io/topics/lru-cache" target="_blank" rel="noopener">Redis Lru Cache</a></li>
<li>负载均衡。用到了集群，就免不了需要用到负载均衡，用什么负载均衡算法？在哪里使用负载均衡？这点大家可以参考：<a href="https://redis.io/topics/partitioning" target="_blank" rel="noopener">Redis Partitioning</a></li>
<li>Presharding。如果一开始只有三台Redis服务器，后来发现需要加多一台才能满足业务需要，要怎么办？Redis提供了一种策略，叫：<a href="https://redis.io/topics/partitioning#presharding" target="_blank" rel="noopener">Presharding</a></li>
<li>数据持久化。如果我的机器突然全部断电了，我的缓存数据还能恢复吗？Redis说，相信我，可以的，不然我怎么用作数据库？去看看这个：<a href="https://redis.io/topics/persistence" target="_blank" rel="noopener">Redis Persistence</a>]</li>
<li>数据同步。这篇文章里提到了主从复制，那么Redis是怎么进行主从复制的呢？根据CAP理论，既然我们已经选择了集群，也就是P，分区容忍性，那么剩下那两个，Consistency和Availability只能选择一个了，那么Redis到底是支持最终一致性还是强一致性呢？可以参考：<a href="https://redis.io/topics/replication" target="_blank" rel="noopener">Redis Replication</a></li>
</ul>
<blockquote>
<p>参考知乎<a href="https://zhuanlan.zhihu.com/p/37055648" target="_blank" rel="noopener">Redis简明教程</a></p>
</blockquote>
]]></content>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/02/15/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
